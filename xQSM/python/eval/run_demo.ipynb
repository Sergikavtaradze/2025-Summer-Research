{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a demo for xQSM;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.io as scio\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from xQSM import *\n",
    "from Unet import *\n",
    "from utils import ssim, psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZeroPadding(Field, factor = 8):\n",
    "    ImSize = np.shape(Field)\n",
    "    UpSize = np.ceil(ImSize / factor) * factor  # calculate the padding size; \n",
    "    pos_init = np.ceil((UpSize - ImSize) / 2) \n",
    "    pos_end = pos_init + ImSize - 1\n",
    "    tmp_Field = np.zeros(UpSize)\n",
    "    tmp_Field[pos_init[1]:pos_end[1], pos_init[2]:pos_end[2], pos_init[3]:pos_end[3]] = Field\n",
    "    Field = tmp_Field\n",
    "    pos = np.zeros([3, 2])\n",
    "    pos[:,0] = pos_init\n",
    "    pos[:,1] = pos_end\n",
    "    return Field, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: ZeroPadding to make the size of the field divisible by the designated factor; \n",
    "          Field: local field map; \n",
    "          pos: the position information of padding; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZeroRemoving(Field, pos):\n",
    "    Field = Field[pos_init[1]:pos_end[1], pos_init[2]:pos_end[2], pos_init[3]:pos_end[3]]\n",
    "    return Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: ZeroRemoving: inverse function of ZeroPadding; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_nii(path):\n",
    "    nibField = nib.load(path)\n",
    "    Field = nibField.get_fdata() \n",
    "    aff = nibField.affine\n",
    "    Field = np.array(Field)\n",
    "    return Field, aff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: read local field map from nifti fils; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_nii(Recon, aff, path):\n",
    "    nibRecon = nib.Nifti1Image(Recon,aff)\n",
    "    nib.save(nibRecon, path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: save the results in nii format; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_mat(Recon, path):\n",
    "    \"\"\"\n",
    "    save the results in mat format; \n",
    "    \"\"\"\n",
    "    scio.savemat(path, {'Recon':Recon})   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: save results in .mat format;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define evaluation function for the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval(Field, NetName):\n",
    "    with torch.no_grad(): \n",
    "        ## Network Load; \n",
    "        print('Load Pretrained Network')\n",
    "        model_weights_path = NetName + '.pth'\n",
    "        if 'xQSM' in NetName:\n",
    "            Net = xQSM(2)\n",
    "        elif 'Unet' in NetName:\n",
    "            Net = Unet(2)\n",
    "        else:\n",
    "            sys.stderr.write('Network Type Invalid!\\n')\n",
    "        if torch.cuda.is_available():  ## if GPU is available; \n",
    "            Net = nn.DataParallel(Net) ## our network is trained with dataparallel wrapper;\n",
    "            Net.load_state_dict(torch.load(model_weights_path))\n",
    "            Net = Net.module\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            Net.to(device)\n",
    "            Net.eval()  ## set the model to evaluation mode\n",
    "            Field = Field.to(device)\n",
    "        else:\n",
    "            weights = torch.load(model_weights_path, map_location='cpu')\n",
    "            new_state_dict = OrderedDict()\n",
    "            print(new_state_dict)\n",
    "            for k, v in weights.items():\n",
    "                ## remove the first 7 charecters  \"module.\" of the network weights \n",
    "                ## files to load the net into cpu, because our network is saved \n",
    "                ## as with dataparallel wrapper. \n",
    "                name = k[7:]  \n",
    "                new_state_dict[name] = v\n",
    "            Net.load_state_dict(new_state_dict)\n",
    "            Net.eval()  ## set the model to evaluation mode\n",
    "        ################ Evaluation ##################\n",
    "        time_start = time.time()\n",
    "        Recon = Net(Field)\n",
    "        time_end = time.time()\n",
    "        print('%f seconds elapsed!' % (time_end - time_start))\n",
    "        Recon = torch.squeeze(Recon, 0)\n",
    "        Recon = torch.squeeze(Recon, 0)\n",
    "        Recon = Recon.to('cpu')  ## transfer to cpu for saving. \n",
    "        Recon = Recon.numpy()\n",
    "    return Recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown: Eval(Field, Netype, Env) retunrs the QSM reconstruction of the local field map (Field)\n",
    "          using a designated Network (NetName); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration on a simulated COSMOS data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    ## Data Load;        \n",
    "    print('Data Loading')   \n",
    "    Field, aff = Read_nii('../../field_input.nii')\n",
    "    print('Loading Completed')\n",
    "    mask = Field != 0 \n",
    "    ## note the size of the field map input needs to be divisibel by the factor\n",
    "    ## otherwise 0 padding should be done first\n",
    "    print('ZeroPadding')\n",
    "    imSize = np.shape(Field)\n",
    "    if np.mod(imSize,  8).any():\n",
    "        Field, pos = ZeroPadding(Field, 8)  # ZeroPadding\n",
    "    Field = torch.from_numpy(Field) \n",
    "    ## The networks in pytorch only supports inputs that are a mini-batch of samples,\n",
    "    ## and not a single sample. Therefore we need  to squeeze the 3D tensor to be \n",
    "    ## a 5D tesor for model evaluation.  \n",
    "    Field = torch.unsqueeze(Field, 0)\n",
    "    Field = torch.unsqueeze(Field, 0)\n",
    "    Field = Field.float()\n",
    "    ## QSM Reconstruction \n",
    "    print('Reconstruction')\n",
    "    Recon_xQSM_invivo = Eval(Field, 'xQSM_invivo')\n",
    "    Recon_Unet_invivo = Eval(Field, 'Unet_invivo')\n",
    "    #Recon_xQSM_syn = Eval(Field, 'xQSM_syn')\n",
    "    #Recon_Unet_syn = Eval(Field, 'Unet_syn')\n",
    "    if np.mod(imSize,  8).any():\n",
    "        Recon_xQSM_invivo  = ZeroRemoving(Recon_xQSM_invivo , pos) # ZeroRemoving if zeropadding were performed; \n",
    "        Recon_Unet_invivo  = ZeroRemoving(Recon_Unet_invivo , pos) \n",
    "    Recon_xQSM_invivo = Recon_xQSM_invivo * mask\n",
    "    Recon_Unet_invivo = Recon_Unet_invivo * mask\n",
    "    ## calculate PSNR and SSIM\n",
    "    label, aff = Read_nii('../../cosmos_label.nii')  # read label; \n",
    "    print('PSNR of xQSM_invivo is %f'% (psnr(Recon_xQSM_invivo, label)))\n",
    "    print('PSNR of Unet_invivo is %f'% (psnr(Recon_Unet_invivo, label)))\n",
    "    ## Saving Results (in .mat)\n",
    "    print('saving reconstructions')\n",
    "    path = './Chi_xQSM_invivo.mat' \n",
    "    Save_mat(Recon_xQSM_invivo, path)\n",
    "    path = './Chi_Unet_invivo.mat' \n",
    "    Save_mat(Recon_Unet_invivo, path)\n",
    "    #path = './Chi_xQSM_syn.mat' \n",
    "    #Save_mat(Recon_xQSM_syn, path)\n",
    "    #path = './Chi_Unet_syn.mat' \n",
    "    #Save_mat(Recon_Unet_syn, path)\n",
    "    ## or can be stored in .nii format; \n",
    "    path = 'Chi_xQSM_invivo.nii'\n",
    "    Save_nii(Recon_xQSM_invivo, aff, path)\n",
    "    path = 'Chi_Unet_invivo.nii'\n",
    "    Save_nii(Recon_Unet_invivo, aff, path)\n",
    "    #path = 'Chi_xQSM_syn.nii'\n",
    "    #Save_nii(Recon_xQSM_syn, aff, path)\n",
    "    #path = 'Chi_Unet_syn.nii'\n",
    "    #Save_nii(Recon_xQSM_invivo, aff, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
